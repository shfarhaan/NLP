{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1fugNG54bNsZEV3qF1kNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shfarhaan/NLP/blob/main/spaCy/spaCy_Tutorial_for_Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **spaCy Tutorial for Natural Language Processing**"
      ],
      "metadata": {
        "id": "yUyQ0h_-NZGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**\n",
        "\n",
        "Python has emerged as a popular language for Natural Language Processing (NLP) due to its simplicity and powerful libraries. One such library is spaCy, which provides easy-to-use and efficient tools for various NLP tasks. This tutorial aims to introduce beginners to spaCy and cover essential NLP tasks using this library.\n"
      ],
      "metadata": {
        "id": "AEgJAB0oNifw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to spaCy"
      ],
      "metadata": {
        "id": "KeSI7f7pNuQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is spaCy?\n",
        "spaCy is an open-source library used for advanced NLP in Python. It is designed with the goal of being fast, streamlined, and simple to use. spaCy offers features for tokenization, named entity recognition (NER), part-of-speech tagging, dependency parsing, and more.\n"
      ],
      "metadata": {
        "id": "41OHgyEYN2kQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wk-klY1SN4jn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Installation\n",
        "To install spaCy, use pip:\n",
        "\n",
        "```bash\n",
        "pip install spacy\n",
        "```"
      ],
      "metadata": {
        "id": "xP6z0YqQNuNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "id": "k5l68-ghN-ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy NLP object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Preprocess the text\n",
        "text = \"This is a sample text.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the tokens\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi7cKONaOCRf",
        "outputId": "94fdb0e6-22ba-42bd-9843-838b7e17a2d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This\n",
            "is\n",
            "a\n",
            "sample\n",
            "text\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Replace `en_core_web_sm` with the language model you want to download. This example uses the English language model."
      ],
      "metadata": {
        "id": "FaGCKLpQOn85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Text Preprocessing with spaCy"
      ],
      "metadata": {
        "id": "1le_3BnHNuKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenization\n",
        "Tokenization breaks text into individual words or tokens. Here's how to tokenize text using spaCy:\n",
        "\n",
        "```python\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"Tokenization breaks text into tokens.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text)\n",
        "```\n"
      ],
      "metadata": {
        "id": "wY0mwtmoOw8i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mOjObAlvOxor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lemmatization\n",
        "Lemmatization reduces words to their base or root form. Here's an example:\n",
        "\n",
        "```python\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_)\n",
        "```\n",
        "\n",
        "#### Part-of-Speech Tagging\n",
        "Identifying the grammatical parts of a sentence using spaCy:\n",
        "\n",
        "```python\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_)\n",
        "```"
      ],
      "metadata": {
        "id": "cB913kAdNuGc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSV5_sFqO1ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Named Entity Recognition (NER)\n",
        "\n",
        "Named Entity Recognition identifies entities in text, such as names, organizations, locations, etc. Example:\n",
        "\n",
        "```python\n",
        "text = \"Apple is situated in California.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n",
        "```"
      ],
      "metadata": {
        "id": "L6o9fwaUNuC-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yI7jIPYqO6Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Dependency Parsing\n",
        "\n",
        "Dependency Parsing reveals the grammatical structure of a sentence. Example:\n",
        "\n",
        "```python\n",
        "for token in doc:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_)\n",
        "```\n"
      ],
      "metadata": {
        "id": "Qpr_6Z9tNt_f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w77mAdGJO8_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 9. Text Classification with spaCy\n",
        "\n",
        "Text classification categorizes text into predefined classes or categories. Here's a simple example:\n",
        "\n",
        "```python\n",
        "# Training data preparation\n",
        "train_texts = [\"Text 1\", \"Text 2\", \"Text 3\"]\n",
        "train_labels = [\"Label 1\", \"Label 2\", \"Label 3\"]\n",
        "\n",
        "# Train a text classification model\n",
        "textcat = nlp.create_pipe(\"textcat\")\n",
        "nlp.add_pipe(textcat, last=True)\n",
        "\n",
        "textcat.add_label(\"Label 1\")\n",
        "textcat.add_label(\"Label 2\")\n",
        "textcat.add_label(\"Label 3\")\n",
        "\n",
        "train_data = list(zip(train_texts, [{\"cats\": {label: 1.0 if label == true_label else 0.0 for label in train_labels}} for true_label in train_labels]))\n",
        "\n",
        "for text, annotations in train_data:\n",
        "    doc = nlp.make_doc(text)\n",
        "    example = Example.from_dict(doc, annotations)\n",
        "    nlp.update([example], losses={textcat: losses.CategoricalCrossentropy()})\n",
        "\n",
        "# Classify new text\n",
        "new_text = \"New text to classify\"\n",
        "doc = nlp(new_text)\n",
        "print(doc.cats)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "ta8LES_cO_xn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUUJLiNuPArX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Practical Examples and Projects\n",
        "\n",
        "#### Project 1: Sentiment Analysis\n",
        "Perform sentiment analysis on a dataset using spaCy for text classification.\n",
        "\n",
        "#### Project 2: Information Extraction\n",
        "Extract specific information, like dates or quantities, from a set of documents using spaCy.\n"
      ],
      "metadata": {
        "id": "BLrF53y9PCYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 11. Conclusion\n",
        "\n",
        "In this tutorial, we covered the basics of Python and spaCy for NLP tasks. We explored text preprocessing, named entity recognition, dependency parsing, text classification, and presented practical examples and projects. To further advance your understanding, continue exploring spaCy's documentation, practice on different datasets, and engage in real-world NLP projects. With consistent practice, you'll become proficient in NLP using Python and spaCy.\n",
        "\n",
        "Remember, NLP is a vast field, and this tutorial only scratches the surface. Continual learning and hands-on experience will enhance your skills and understanding.\n",
        "\n",
        "I hope this tutorial serves as a solid foundation for your journey into NLP with spaCy and Python."
      ],
      "metadata": {
        "id": "WuDLmScvNVcZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqROeqtnNTHN"
      },
      "outputs": [],
      "source": []
    }
  ]
}