{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shfarhaan/NLP/blob/main/NLP_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fundamental concepts of NLP\n",
        "\n",
        "**NLP** is a field of computer science that deals with the interaction between computers and human (natural) languages. It's concerned with giving computers the ability to understand and generate human language, including speech and text.\n",
        "\n",
        "**Fundamental concepts of NLP** include:\n",
        "\n",
        "1. **Tokenization**:\n",
        "   - **Definition**: Tokenization is the process of breaking a text into individual words or tokens.\n",
        "   - **Example**: In the sentence \"I love NLP,\" tokenization would break it into the tokens \"I,\" \"love,\" and \"NLP.\"\n",
        "\n",
        "2. **Text Preprocessing**:\n",
        "   - **Definition**: Text preprocessing involves tasks like removing stop words, punctuation, and converting text to lowercase to make it more suitable for analysis.\n",
        "   - **Example**: In the sentence \"The quick brown dog jumped over the lazy dog,\" preprocessing might remove \"the\" and convert all words to lowercase, resulting in \"quick brown dog jumped over lazy dog.\"\n",
        "\n",
        "3. **Part-of-Speech (POS) Tagging**:\n",
        "   - **Definition**: POS tagging assigns grammatical tags (e.g., noun, verb, adjective) to each word in a sentence.\n",
        "   - **Example**: In the sentence \"She quickly reads a book,\" POS tagging would label \"She\" as a pronoun, \"quickly\" as an adverb, \"reads\" as a verb, and \"book\" as a noun.\n",
        "\n",
        "4. **Named Entity Recognition (NER)**:\n",
        "   - **Definition**: NER identifies and categorizes named entities in text, such as names of people, places, organizations, and dates.\n",
        "   - **Example**: In the text \"Apple Inc. was founded by Steve Jobs and Steve Wozniak on April 1, 1976,\" NER would recognize \"Apple Inc.\" as an organization, \"Steve Jobs\" and \"Steve Wozniak\" as persons, and \"April 1, 1976\" as a date.\n",
        "\n",
        "5. **Sentiment Analysis**:\n",
        "   - **Definition**: Sentiment analysis determines the emotional tone or sentiment expressed in a piece of text, such as positive, negative, or neutral.\n",
        "   - **Example**: Analyzing the review \"The movie was amazing! I loved it!\" would result in a positive sentiment.\n",
        "\n",
        "6. **Machine Translation**:\n",
        "   - **Definition**: Machine translation is the process of automatically translating text from one language to another.\n",
        "   - **Example**: Translating \"Bonjour, comment Ã§a va?\" from French to English would yield \"Hello, how are you?\"\n",
        "\n",
        "7. **Text Generation**:\n",
        "   - **Definition**: Text generation techniques, like language modeling, are used to generate coherent and contextually relevant text based on given input.\n",
        "   - **Example**: A chatbot might generate responses like \"Sure, I can help you with that!\" in response to user queries.\n",
        "\n",
        "8. **Topic Modeling**:\n",
        "   - **Definition**: Topic modeling is a technique to identify topics or themes in a collection of documents.\n",
        "   - **Example**: Analyzing a set of news articles may reveal topics like \"politics,\" \"sports,\" and \"technology\" as dominant themes.\n",
        "\n",
        "9. **Word Embeddings**:\n",
        "   - **Definition**: Word embeddings represent words as dense vectors in a continuous vector space, capturing semantic relationships between words.\n",
        "   - **Example**: Words with similar meanings, like \"cat\" and \"kitten,\" have similar word embeddings, making them close in the vector space.\n",
        "\n",
        "10. **Language Models**:\n",
        "    - **Definition**: Language models are models that predict the probability of the next word in a sequence based on the previous words, enabling tasks like text generation and completion.\n",
        "    - **Example**: The GPT-3 model can complete the prompt \"Once upon a time, there was a...\" with coherent and contextually relevant text.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "293wRzr4DkxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "(ROOT\n",
        "  (S\n",
        "    (NP (PRP I))\n",
        "    (VP (VBZ am)\n",
        "      (VP (VBG walking)\n",
        "        (PP (TO to)\n",
        "          (NP (DT the) (NN store)))))\n",
        "```\n"
      ],
      "metadata": {
        "id": "ZtFZr5gBDkxu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
