{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMncLdmwVFfIcFwBWDLaNqp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shfarhaan/NLP/blob/main/spaCy_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 1:**\n",
        "\n",
        "Finding words, phrases, names and concepts\n",
        "\n",
        "This chapter will introduce you to the basics of text processing with spaCy. You'll learn about the data structures, how to work with trained pipelines, and how to use them to predict linguistic features in your text.\n"
      ],
      "metadata": {
        "id": "pwgxXeImwUXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy"
      ],
      "metadata": {
        "id": "XtQbkS5qvkVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the center of spaCy is the object containing the processing pipeline. We usually call this variable \"nlp\".\n",
        "\n",
        "For example, to create an English nlp object, you can import spacy and use the spacy.blank method to create a blank English pipeline. You can use the nlp object like a function to analyze text. It contains all the different components in the pipeline.\n",
        "\n",
        "It also includes language-specific rules used for tokenizing the text into words and punctuation. spaCy supports a variety of languages."
      ],
      "metadata": {
        "id": "7XY3-ETWyTyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import spaCy\n",
        "import spacy\n",
        "\n",
        "# Create a blank English nlp object\n",
        "nlp = spacy.blank(\"en\")"
      ],
      "metadata": {
        "id": "EbuHEchhvjT6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Doc object**\n",
        "\n",
        "When you process a text with the `nlp` object, spaCy creates a Doc object – short for \"document\". The `Doc` lets you access information about the text in a structured way, and no information is lost.\n",
        "\n",
        "The Doc behaves like a normal Python sequence by the way and lets you iterate over its tokens, or get a token by its index. But more on that later!"
      ],
      "metadata": {
        "id": "0VFDyfbzv37Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6gko1SHvOrR",
        "outputId": "b31b4c56-93cb-466e-df60-7babb84ace26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "world\n",
            "!\n"
          ]
        }
      ],
      "source": [
        "# Created by processing a string of text with the nlp object\n",
        "doc = nlp(\"Hello world!\")\n",
        "\n",
        "# Iterate over tokens in a Doc\n",
        "for token in doc:\n",
        "    print(token.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Token object**\n",
        "\n",
        "![Illustration of a Doc object containing three tokens](https://course.spacy.io/doc.png)\n",
        "\n",
        "`Token` objects represent the tokens in a document – for example, a word or a punctuation character.\n",
        "\n",
        "To get a token at a specific position, you can index into the doc.\n",
        "\n",
        "Token objects also provide various attributes that let you access more information about the tokens. For example, the .text attribute returns the verbatim token text.\n"
      ],
      "metadata": {
        "id": "kdiSPN3zzUur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Hello world!\")\n",
        "\n",
        "# Index into the Doc to get a single Token\n",
        "token = doc[1]\n",
        "\n",
        "# Get the token text via the .text attribute\n",
        "print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb8tP2o3vw64",
        "outputId": "6fbf8a64-727a-4221-d6e8-d480c41473a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Span object**\n",
        "\n",
        "![Illustration of a Doc object containing three tokens and two of them wrapped in a Span](https://course.spacy.io/doc_span.png)\n",
        "\n",
        "A `Span` object is a slice of the document consisting of one or more tokens. It's only a view of the Doc and doesn't contain any data itself.\n",
        "\n",
        "To create a span, you can use Python's slice notation. For example, 1:3 will create a slice starting from the token at position 1, up to – but not including! – the token at position 3."
      ],
      "metadata": {
        "id": "ctS1dkhx08Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Hello world!\")\n",
        "\n",
        "# A slice from the Doc is a Span object\n",
        "span = doc[1:3]\n",
        "\n",
        "# Get the span text via the .text attribute\n",
        "print(span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glBm0Ph303fn",
        "outputId": "4f083dbc-a070-42fc-9f6f-3469462cd05d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "world!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lexical Attributes**\n",
        "\n",
        "Here you can see some of the available token attributes:\n",
        "\n",
        "`i` is the index of the token within the parent document.\n",
        "\n",
        "`text` returns the token text.\n",
        "\n",
        "`is_alpha`, `is_punct` and `like_num` return boolean values indicating whether the token consists of alphabetic characters, whether it's punctuation or whether it resembles a number. For example, a token \"10\" – one, zero – or the word \"ten\" – T, E, N.\n",
        "\n",
        "These attributes are also called lexical attributes: they refer to the entry in the vocabulary and don't depend on the token's context."
      ],
      "metadata": {
        "id": "GyPKdaoC1g6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"It costs $5.\")\n",
        "print(\"Index:   \", [token.i for token in doc])\n",
        "print(\"Text:    \", [token.text for token in doc])\n",
        "\n",
        "print(\"is_alpha:\", [token.is_alpha for token in doc])\n",
        "print(\"is_punct:\", [token.is_punct for token in doc])\n",
        "print(\"like_num:\", [token.like_num for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3bjagmH1dFA",
        "outputId": "07eb9709-30e8-4d37-c29e-b5a48bfb400e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index:    [0, 1, 2, 3, 4]\n",
            "Text:     ['It', 'costs', '$', '5', '.']\n",
            "is_alpha: [True, True, False, False, False]\n",
            "is_punct: [False, False, False, False, True]\n",
            "like_num: [False, False, False, True, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yfqZvAmN16P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practice**"
      ],
      "metadata": {
        "id": "QAy_mtMS15Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import spaCy\n",
        "import spacy\n",
        "\n",
        "# Create the English nlp object\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Process a text\n",
        "doc = nlp(\"This is a sentence.\")\n",
        "\n",
        "# Print the document text\n",
        "print(doc.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbQzfufY11tp",
        "outputId": "10e675b0-9ea7-4fa8-d9d4-a7d25fa80f79"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import spaCy and create the English nlp object\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
        "\n",
        "# Select the first token\n",
        "first_token = doc[0]\n",
        "\n",
        "# Print the first token's text\n",
        "print(first_token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu1ofwDX2JB0",
        "outputId": "06fff130-6cbc-47c2-b117-3e899fb3ad2b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import spaCy and create the English nlp object\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
        "\n",
        "# A slice of the Doc for \"tree kangaroos\"\n",
        "tree_kangaroos = doc[2:4]\n",
        "print(tree_kangaroos.text)\n",
        "\n",
        "# A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\n",
        "tree_kangaroos_and_narwhals = doc[2:6]\n",
        "print(tree_kangaroos_and_narwhals.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzPZXN_y6DGW",
        "outputId": "dd3a48a7-3233-4fc7-a711-68b1a8fcc530"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tree kangaroos\n",
            "tree kangaroos and narwhals\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7ZXBxEz6im7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}